Chapter 1

Introduction

The idea that we learn by interacting with our environment is probably the first to occur to use when we think about the nature of learning. When an infant plays, waves its arms, or looks about, it has no explicit teacher, but it does have a direct sensorimotor connection to its environment. Exercising this connection ..


1.1 Reinforcement Learning

Reinforcement learning is learning what to do - how to map situations to actions - so as to maximize a numerical reward signal. The learner is not told which actions to take, but instead must discover which actions yield the most reward by trying them. In the most interesting and challenging cases, actions may affect not only the immediate reward but also the next situation and, through that, all subsequent rewards. These two characteristics - trial-and-error search and delayed reward - are the two most important distinguishing features of reinforcement learning.

Reinforcement learning, like many topics whose names end with "ing", such as machine learning and mountaineering, is simultaneously a problem, a class of ...

A learning agent must be able to sense the state of its environment to some extent and must be able to take actions that affect the state. The agent also must have a goal or goals relating to the state of the environment.

{ Reinforcement Learning's challenges: }
(1): trade off between exploration and exploitation, 


It is values with which we are most concerned when making and evaluating decisions. Action choices are made based on value judgments. We seek actions that bring about states of highest value, not highest reward, because these actions obtain the greatest amount of reward for us over the long run. Unfortunately, it is much harder to determine values than it is to determine rewards. Rewards are basically given directly by the environment, but values must be estimated and re-estimated from sequences of observations an agent makes over its entire lifetime.

The fourth and final elemnt of some reinforcement learning systems is a model of the environment. This is something that mimics the behavior of the environment, or more generally, that allows inferences to be made about how the environment will behave. For example, given a state and action for current time step t, the model might predict the resultant next state and next reward. Models are used for planning, by which we mean any way of deciding on a course of 


1.4 Limitations and Scope;

Reinforcement learning relies heavily on the concept of state - as input to the policy and value function, and as both input to and output from the model (state transition). Informally, we can think of the state as a signal conveying to the agent some sense of "how the environment is" at a particular time. ... In effect, we assume that the state signal is produced by some preprocessing system that is nominally part of the agent's environment. In other words, our concern in this book is not with designing the state signal, but with deciding what action to take as a function of whatever state signal is available.
{看一下计老师对于state的来源，because textbook simply treats the state as a signal preprocessed by environment in a mysterious way. Textbooks prefer to focus on: "given available state signal, how to confirm a policy function to decide what actions to be made"}

Most of the reinforcement learning methods we consider in this book are structured around estimating value functions, but it is not strictly necessary to do this to solve reinforcement learning problems.

